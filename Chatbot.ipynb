{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1619672516164,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "UJ05fENIU2QA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5992,
     "status": "ok",
     "timestamp": 1619675189946,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "g1Cix72N_jBF",
    "outputId": "642f1aba-2a27-4b63-9164-004145c57c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "30000\n",
      "3797\n",
      "3797\n"
     ]
    }
   ],
   "source": [
    "# Data Load\n",
    "\n",
    "from retrieve_data import *\n",
    "\n",
    "\n",
    "cornell_utt, cornell_res = cornell('data/cornell movie-dialogs corpus')\n",
    "himym_utt, himym_res = himym('data/HIMYM')\n",
    "\n",
    "print(len(cornell_utt))\n",
    "print(len(cornell_res))\n",
    "\n",
    "print(len(himym_utt))\n",
    "print(len(himym_utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 669,
     "status": "ok",
     "timestamp": 1619673125154,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "7ob3D8lmBOxP"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "ans = np.append(cornell_res, himym_res)\n",
    "ques = np.append(cornell_utt, himym_utt)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1619675221241,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "zEhf-DzjVT1-"
   },
   "outputs": [],
   "source": [
    "###  count occurences ###\n",
    "\n",
    "ques = cornell_utt\n",
    "ans = cornell_res\n",
    "\n",
    "word2count = {}\n",
    "\n",
    "for line in ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for line in ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "\n",
    "\n",
    "###  remove less frequent ###\n",
    "thresh = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1\n",
    "        \n",
    "\n",
    "\n",
    "for i in range(len(ans)):\n",
    "    ans[i] = '<SOS> ' + ans[i] + ' <EOS>'\n",
    "\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "\n",
    "x = len(vocab)\n",
    "\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1\n",
    "    \n",
    "\n",
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "\n",
    "### inv answers dict ###\n",
    "inv_vocab = {w:v for v, w in vocab.items()}\n",
    "\n",
    "\n",
    "encoder_inp = []\n",
    "for line in ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = []\n",
    "for line in ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "decoder_final_output = []\n",
    "\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) \n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1619675228825,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "GvsShEIxVT-N",
    "outputId": "0ab0bc95-b603-4949-b583-b925d0339614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13) (30000, 13) (30000, 13) 3166 3165 <PAD>\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "MAX_LEN = 13\n",
    "\n",
    "print(decoder_final_output.shape, decoder_inp.shape, encoder_inp.shape, len(vocab), len(inv_vocab), inv_vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1791,
     "status": "ok",
     "timestamp": 1619675234870,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "tNmcxb5hVUZc",
    "outputId": "296cc458-f1ab-4cb8-99e2-0766caa4c6d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 13, 3166)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "decoder_final_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 6156,
     "status": "ok",
     "timestamp": 1619675243622,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "Kuj7PxabVUfP"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "with open('data/glove.6B.50d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1619675245551,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "8K3QTk5kVUjQ"
   },
   "outputs": [],
   "source": [
    "embedding_dimention = 50\n",
    "\n",
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index)+1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "embedding_matrix = embedding_matrix_creater(50, word_index=vocab)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1619675248775,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "rx-TS0lhVVA9",
    "outputId": "d62f8b5f-4765-4b40-d0f8-4c83f2c4daf2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3167, 50)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1619675252134,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "cKChcKQ7VVZA",
    "outputId": "cd22da40-3007-4919-925d-e9ec9e173257"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.18000013e-01,  2.49679998e-01, -4.12420005e-01,  1.21699996e-01,\n",
       "        3.45270008e-01, -4.44569997e-02, -4.96879995e-01, -1.78619996e-01,\n",
       "       -6.60229998e-04, -6.56599998e-01,  2.78430015e-01, -1.47670001e-01,\n",
       "       -5.56770027e-01,  1.46579996e-01, -9.50950012e-03,  1.16579998e-02,\n",
       "        1.02040000e-01, -1.27920002e-01, -8.44299972e-01, -1.21809997e-01,\n",
       "       -1.68009996e-02, -3.32789987e-01, -1.55200005e-01, -2.31309995e-01,\n",
       "       -1.91809997e-01, -1.88230002e+00, -7.67459989e-01,  9.90509987e-02,\n",
       "       -4.21249986e-01, -1.95260003e-01,  4.00710011e+00, -1.85939997e-01,\n",
       "       -5.22870004e-01, -3.16810012e-01,  5.92130003e-04,  7.44489999e-03,\n",
       "        1.77780002e-01, -1.58969998e-01,  1.20409997e-02, -5.42230010e-02,\n",
       "       -2.98709989e-01, -1.57490000e-01, -3.47579986e-01, -4.56370004e-02,\n",
       "       -4.42510009e-01,  1.87849998e-01,  2.78489990e-03, -1.84110001e-01,\n",
       "       -1.15139998e-01, -7.85809994e-01])"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1619675260608,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "0eqg5aSfVS8m"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input, Bidirectional, Concatenate, Dropout, Attention\n",
    "\n",
    "\n",
    "embed = Embedding(VOCAB_SIZE+1, 50, \n",
    "                  input_length=13,\n",
    "                  trainable=True)\n",
    "\n",
    "embed.build((None,))\n",
    "\n",
    "embed.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1991,
     "status": "ok",
     "timestamp": 1619675265416,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "mrZ784q_VS6A",
    "outputId": "7c7ff24c-d707-4e3d-8d40-ba39ff15e572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 13, 50)       158350      input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) [(None, 13, 800), (N 1443200     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 800)          0           bidirectional_4[0][1]            \n",
      "                                                                 bidirectional_4[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 800)          0           bidirectional_4[0][2]            \n",
      "                                                                 bidirectional_4[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 13, 800), (N 2723200     embedding_3[1][0]                \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_3 (AttentionLay ((None, 13, 800), (N 1280800     bidirectional_4[0][0]            \n",
      "                                                                 lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 13, 1600)     0           lstm_9[0][0]                     \n",
      "                                                                 attention_layer_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 13, 3166)     5068766     concatenate_13[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 10,674,316\n",
      "Trainable params: 10,674,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from attention import AttentionLayer\n",
    "\n",
    "# Model\n",
    "enc_inp = Input(shape=(13, ))\n",
    "\n",
    "\n",
    "#embed = Embedding(VOCAB_SIZE+1, 50, mask_zero=True, input_length=13)(enc_inp)\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = Bidirectional(LSTM(400, return_state=True, dropout=0.05, return_sequences = True))\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = enc_lstm(enc_embed)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "\n",
    "enc_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "dec_inp = Input(shape=(13, ))\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400*2, return_state=True, return_sequences=True, dropout=0.05)\n",
    "output, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "# attention\n",
    "attn_layer = AttentionLayer()\n",
    "attn_op, attn_state = attn_layer([encoder_outputs, output])\n",
    "decoder_concat_input = Concatenate(axis=-1)([output, attn_op])\n",
    "\n",
    "\n",
    "dec_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "final_output = dec_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], final_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1619675272597,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "ng2AYE02VS3q"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404343,
     "status": "ok",
     "timestamp": 1619675678881,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "RtHIn0x8VS0q",
    "outputId": "ae480095-40bb-4734-8b0a-c30db02691e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1063/1063 [==============================] - 47s 39ms/step - loss: 1.2651 - acc: 0.8033 - val_loss: 0.9504 - val_acc: 0.8385\n",
      "Epoch 2/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.9202 - acc: 0.8360 - val_loss: 0.9142 - val_acc: 0.8445\n",
      "Epoch 3/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.8580 - acc: 0.8393 - val_loss: 0.9022 - val_acc: 0.8448\n",
      "Epoch 4/10\n",
      "1063/1063 [==============================] - 39s 37ms/step - loss: 0.8128 - acc: 0.8424 - val_loss: 0.8995 - val_acc: 0.8473\n",
      "Epoch 5/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.7556 - acc: 0.8466 - val_loss: 0.9020 - val_acc: 0.8473\n",
      "Epoch 6/10\n",
      "1063/1063 [==============================] - 40s 38ms/step - loss: 0.6998 - acc: 0.8518 - val_loss: 0.9170 - val_acc: 0.8476\n",
      "Epoch 7/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.6349 - acc: 0.8597 - val_loss: 0.9364 - val_acc: 0.8471\n",
      "Epoch 8/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.5656 - acc: 0.8697 - val_loss: 0.9670 - val_acc: 0.8462\n",
      "Epoch 9/10\n",
      "1063/1063 [==============================] - 40s 37ms/step - loss: 0.4899 - acc: 0.8820 - val_loss: 0.9961 - val_acc: 0.8452\n",
      "Epoch 10/10\n",
      "1063/1063 [==============================] - 39s 37ms/step - loss: 0.4165 - acc: 0.8981 - val_loss: 1.0386 - val_acc: 0.8432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8422e4b550>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp], decoder_final_output, epochs=10, batch_size=24, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1619675681386,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "lQhkCNx9GNpo"
   },
   "outputs": [],
   "source": [
    "model.save('model_03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dt-4NAy7PHMr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1619675683701,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "QxN26IdEVSvU"
   },
   "outputs": [],
   "source": [
    "enc_model = tf.keras.models.Model(enc_inp, [encoder_outputs, enc_states])\n",
    "\n",
    "\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=( 400 * 2,))\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=( 400 * 2,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , initial_state=decoder_states_inputs)\n",
    "\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "#decoder_output = dec_dense(decoder_outputs)\n",
    "\n",
    "dec_model = tf.keras.models.Model([dec_inp, decoder_states_inputs],\n",
    "                                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 660739,
     "status": "error",
     "timestamp": 1619676346288,
     "user": {
      "displayName": "moon Song",
      "photoUrl": "",
      "userId": "04638093581814122146"
     },
     "user_tz": -540
    },
    "id": "VTO812NBVSsc",
    "outputId": "70b5b756-b135-4e94-a6a2-b073f34158d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################\n",
      "#     Start chatting with chatbot :)     #\n",
      "##########################################\n",
      "Me : hi\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_14'), name='input_14', description=\"created by layer 'input_14'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "chatbot :  hi \n",
      "============================================================\n",
      "Me : who are you?\n",
      "chatbot :  i am just <OUT> \n",
      "============================================================\n",
      "Me : good to meet you\n",
      "chatbot :  <OUT> <OUT> \n",
      "============================================================\n",
      "Me : can you say something to me?\n",
      "chatbot :  yes \n",
      "============================================================\n",
      "Me : then just say it!\n",
      "chatbot :  i am not \n",
      "============================================================\n",
      "Me : not what?\n",
      "chatbot :  you know something \n",
      "============================================================\n",
      "Me : No I don't\n",
      "chatbot :  you remember \n",
      "============================================================\n",
      "Me : remember what?\n",
      "chatbot :  what \n",
      "============================================================\n",
      "Me : are you kidding me?\n",
      "chatbot :  yes \n",
      "============================================================\n",
      "Me : okay that was funny\n",
      "chatbot :  run into josh \n",
      "============================================================\n",
      "Me : who is josh\n",
      "chatbot :  what \n",
      "============================================================\n",
      "Me : okay bye\n",
      "chatbot :  okay \n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-93277d0e83c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mprepro1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Me : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprepro1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepro1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"#     Start chatting with chatbot :)     #\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "\n",
    "prepro1 = \"\"\n",
    "while prepro1 != 'q':\n",
    "    \n",
    "    prepro1 = input(\"Me : \")\n",
    "    try:\n",
    "        prepro1 = clean_text(prepro1)\n",
    "        prepro = [prepro1]\n",
    "        \n",
    "        txt = []\n",
    "        for x in prepro:\n",
    "            lst = []\n",
    "            for y in x.split():\n",
    "                try:\n",
    "                    lst.append(vocab[y])\n",
    "                except:\n",
    "                    lst.append(vocab['<OUT>'])\n",
    "            txt.append(lst)\n",
    "        txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "\n",
    "        enc_op, stat = enc_model.predict( txt )\n",
    "\n",
    "        empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "        empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "\n",
    "\n",
    "        while not stop_condition :\n",
    "\n",
    "            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + stat )\n",
    "\n",
    "            ###########################\n",
    "            attn_op, attn_state = attn_layer([enc_op, dec_outputs])\n",
    "            decoder_concat_input = Concatenate(axis=-1)([dec_outputs, attn_op])\n",
    "            decoder_concat_input = dec_dense(decoder_concat_input)\n",
    "            ###########################\n",
    "\n",
    "            sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
    "\n",
    "            sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "            if sampled_word != '<EOS> ':\n",
    "                decoded_translation += sampled_word           \n",
    "\n",
    "\n",
    "            if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "                stop_condition = True\n",
    "\n",
    "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "            stat = [ h , c ] \n",
    "\n",
    "        print(\"chatbot : \", decoded_translation )\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "    except:\n",
    "        print(\"sorry didn't got you , please type again :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5OqUbu3VShY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOp9mGL9PeJ6rwzoRKx6PM3",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1KIXXzpQ-FOTcSS0ZetSIH76nlWgzfavo",
   "name": "Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
